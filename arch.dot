digraph ethane {

   node [shape=record];

   PIG_ANALYTICS [label="PIG_ANALYTICS|Unstructured-unsupported-pigscripts|(unknown output paths)"];

   CUSTOMER_PAGE [label="CUSTOMER_PAGE|json|CUSTOMER_PAGE/part*"];
   DIRTY_CSV [label="DIRTY_CSV|fname   lname -prod , price ,prod,..|generated/part*"];
   CSV [label="CSV|fname,lname,prod,price,date,xcoord,ycoord,...|cleaned/part*"];
   MAHOUT_VIEW_INPUT [label="MAHOUT_VIEW  | jay vyas, dogfood, .6 |  <hive_warehouse>/mahout_cf_in/part*" ];
   MAHOUT_CF [label="MAHOUT_CF  | jay vyas, recommended = dog leash, .6 | mahout_cf_out/part*" ];
   PROD_HASH [shape=diamond label="PRODUCT->int"];   
   USER_HASH [shape=diamond label="USER->int"];

   Generate -> DIRTY_CSV [label="hadoop jar bigpetstore.jar org.bigtop.bigpetstore.generator.BPSGenerator 100 bps/generated/"] ;
   DIRTY_CSV -> pig [label=""];  
   
   pig -> CSV [label="hadoop jar bigpetstore.jar org.bigtop.bigpetstore.etl.PigCSVCleaner bps/generated/ bps/cleaned/"];
   pig -> PIG_ANALYTICS [label="same as CSV job, but add your scripts to end... p1.pig p2.pig ..."];
   PIG_ANALYTICS -> CSV;
   PROD_HASH -> pig [label="int val for collab classifier"];
   USER_HASH -> pig  [label="int val for collab classifier"];
   
   CSV -> hive ; 
   hive -> MAHOUT_VIEW_INPUT [label="hadoop jar bigpetstore.jar org.bigtop.bigpetstore.etl.HiveViewCreator bps/pig_out mahout_cf_in"];          
   MAHOUT_VIEW_INPUT -> mahout_collab_filter_recomender  -> MAHOUT_CF;
   MAHOUT_CF  -> crunch ;
   CSV -> crunch ; 
   crunch -> CUSTOMER_PAGE [label="high performance joining"];

}
        
